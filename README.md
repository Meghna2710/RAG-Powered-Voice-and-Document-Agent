🎧 RAG-Powered Voice & Document Agent

This project is an intelligent, AI-powered assistant that allows users to ask questions from uploaded documents (PDF, DOCX, TXT) or audio files (e.g., meetings, lectures). It uses Retrieval-Augmented Generation (RAG) to extract and generate accurate, context-based answers from content, making it ideal for summarizing recordings, reviewing lecture notes, or automating document comprehension.

---

 🚀 Features

- 📄 Upload and query documents (PDF, DOCX, TXT)
- 🔊 Upload audio files — converts **speech to text** automatically using Whisper
- ❓ Ask natural language questions about the uploaded content
- 🤖 Uses **Retrieval-Augmented Generation (RAG)** for better context-aware answers
- 🧠 Maintains conversational context with memory buffer
- 🔍 Accurate, relevant answers — no need to manually read documents or transcriptions
- 🌐 Works locally via Streamlit UI

---

 🧠 Tech Stack

| Component        | Technology                         |
|------------------|-------------------------------------|
| UI               | Streamlit                          |
| LLM              | HuggingFace (Flan-T5)              |
| RAG Engine       | LangChain (ConversationalRetrievalChain) |
| Embeddings       | HuggingFace Embeddings (MiniLM)    |
| Vector Store     | ChromaDB                           |
| Audio Transcription | OpenAI Whisper                    |
| Document Parsing | LangChain loaders (PDF, DOCX, TXT) |
| Memory           | LangChain's ConversationBufferMemory |

---

📸 Demo

<img width="1523" alt="image" src="https://github.com/user-attachments/assets/df4d0fd0-d53f-455f-a5e4-0b4a5cfc1ca3" />

<img width="1518" alt="image" src="https://github.com/user-attachments/assets/6d4c946d-ea54-4c9a-bcd2-2a760428d9b2" />


---

📁 Folder Structure

rag_voice_agent/
│
├── app.py # Main Streamlit app
├── backend/
│ ├── audio_transcriber.py # Whisper-based transcription
│ ├── file_ingestor.py # Document processing
│ ├── vector_store.py # Embedding & ChromaDB logic
│ ├── rag_chain.py # RAG chain with custom prompt
│ └── memory_manager.py # Conversation memory
├── db/ # Local persistent vector store
└── requirements.txt # Dependencies

## ✅ How It Works

1. Upload a document or audio file from the sidebar.
2. The audio is transcribed (if applicable) and text is processed into chunks.
3. Embeddings are generated and stored in ChromaDB.
4. You can then ask questions — responses are generated by the LLM with context-aware retrieval.

---

📦 Setup Instructions

1. Clone the repo

  https://github.com/Meghna2710/RAG-Powered-Voice-and-Document-Agent.git

  cd rag-voice-agent
  
2. Create and activate a virtual environment

  python3 -m venv venv
  
  source venv/bin/activate
  
3. Install dependencies

  pip install -r requirements.txt
  
4. Run the app

  streamlit run app.py

---

📌 Use Cases
Summarize long lecture or meeting audio

Q&A on research papers or reports

Assistive tool for students and professionals

Explore documents in a chat-like interface

